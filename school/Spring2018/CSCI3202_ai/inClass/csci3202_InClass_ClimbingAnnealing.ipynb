{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3202, Spring 2018\n",
    "\n",
    "# Wednesday 14 - Friday 16 February 2018\n",
    "\n",
    "# In-class notebook:  Hill-Climbing and Simulated Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name(s):\n",
    "\n",
    "<br>\n",
    "\n",
    "* When you submit this to Moodle (under Quizlet 5), be sure to include all of your group members' names.\n",
    "* You may work in groups of up to 3 people,\n",
    "* but **all people** in the group must submit the assignment on their own Moodle account (because Moodle is a pain in the ass to create groups and this will still be faster than your normal quizlets).\n",
    "\n",
    "---\n",
    "\n",
    "Shortcuts:  [Top](#top) || [1](#p1) | [1a](#p1a) | [1b](#p1b) | [1c](#p1c) | [1d](#p1d) | [1e](#p1e) || [2](#p2) | [2a](#p2a) | [2b](#p2b) | [2c](#p2c) | [2d](#p2d) || [Bottom](#bottom)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's load a few packages that we might find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"http://1.bp.blogspot.com/-mWUxSF7q_JY/Vbd84OcwaSI/AAAAAAAA7No/5iT8gMZBHw8/s1600/seilschaft2---helliventures-joachimhellinger.jpg=\" width=\"300\"/>\n",
    "\n",
    "<a/ id='p1'></a>\n",
    "\n",
    "## Problem 1: Hill-climbing\n",
    "\n",
    "The over-arching goal here is to maximize some objective function.  You can also look at this as minimizing some kind of a loss... and you will!\n",
    "\n",
    "In many applications, the objective function might turn out to be a Gaussian function, such as this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_objective(state):\n",
    "    return stats.norm.pdf(x=state, loc=5, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the this objective function is just taking in some value $\\texttt{state}$ and returning the value of the normal probability density function, centered at $\\texttt{loc} = \\mu = 5$ and with standard deviation $\\texttt{scale} = \\sigma = 2$:\n",
    "$$f(\\texttt{state}) = \\dfrac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\dfrac{(\\texttt{state}-\\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For good measure, let's plot this thing up and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5,15,0.1)\n",
    "f = [gaussian_objective(state) for state in x]\n",
    "\n",
    "plt.plot(x,f)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Objective function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat.\n",
    "\n",
    "<br>\n",
    "\n",
    "The first order of business if we want to maximize some objective function using the **local search** techniques we just learned will be to set up a class structure to make this easier.\n",
    "\n",
    "If we do this in a general enough way for **hill-climbing** (this first part), we will only need to modify a few things to tackle a trickier problem using **simulated annealing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p1a'></a>\n",
    "\n",
    "### (1a)  A class structure to solve problems\n",
    "\n",
    "So first, let's define a class to keep track of the `state`.  This is the quantity we want to adjust in order to optimize the objective function.  That sentence indicates the two values we really need to keep track of for a `state`:\n",
    "1. the value of `state`\n",
    "2. the value of the `objective_function` when evaluated at `state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class state:\n",
    "\n",
    "    # we need to be able to keep track of states and their associated\n",
    "    # objective function values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define our problem.  This should be entirely self-contained, so that we need to feed the `hill_climb` optimization routine below a fairly generic problem description, and it can solve it, so we can easily feed in different problems.\n",
    "\n",
    "**The goal** with this class structure is to have everything that is **problem-specific** sent into the hill-climbing optimization/local search be self-contained within the `problem` object.\n",
    "\n",
    "We can also write a general problem class, which we might then ***sub-class*** for our specific needs for hill-climbing or simulated annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class problem:\n",
    "\n",
    "    # We want to include everything that defines the problem here:\n",
    "    # - initial state\n",
    "    # - current state\n",
    "    # - what is the objective function we're trying to maximize/minimize?\n",
    "    # - what are the choices of action that we have?\n",
    "    # - what do we need to know to select our action?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can turn our Hill-climbing pseudocode into real code, that takes only two arguments and returns the `state` that optimizes the `objective_function`.  Note that the return can be done implicitly by manipulating the current state within our `problem`, or we could code it up as an explicit output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hill_climb(problem, number of iterations):\n",
    "    \n",
    "    for t in some number of iterations:\n",
    "        #1. get a list of our available moves\n",
    "        #2. which move optimizes the objective function?\n",
    "        #3. do that move; update our state\n",
    "        #4. possible goal/convergence check\n",
    "\n",
    "class problem_hillclimb(problem):\n",
    "    \n",
    "    # let's subclass this like it's hot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p1b'></a>\n",
    "\n",
    "### (1b)  Ready to solve!\n",
    "\n",
    "Let's start by creating an `initial_state` for our problem.  Here, we are beginning at `state` = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_state = state(node=1, value=gaussian_objective(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need an instance of our `problem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_problem = problem_hillclimb(initial=initial_state, objective_function=gaussian_objective, stepsize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can turn out `hill_climb` algorithm loose on this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hill_climb(gaussian_problem, n_iter=50)\n",
    "print(out.node, out.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple extensions\n",
    "\n",
    "That's good and all, but that particular objective function was just a single univariate Gaussian.  It turns out that the real world is tougher than that.  So let's tackle some tougher problems, shall we?\n",
    "\n",
    "<a/ id='p1c'></a>\n",
    "\n",
    "### (1c) Minimization\n",
    "\n",
    "First, it might be the case that we want to ***minimize*** an objective function instead of maximizing it.  Modify your hill-climbing codes to tackle the problem of minimization.  Note:  this ought to be do-able by modifying a single line of code from above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **define your own** objective function to minimize!  Easy options include concave-up quadratic functions just slapping a $-$ sign into the Gaussian objective function defined above.  Then turn your descent algorithm loose on the minimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p1d'></a>\n",
    "\n",
    "### (1d)  Random restarts\n",
    "\n",
    "That single Gaussian actually covers many real-world applications of optimization and local search, but many other applications lead to \"bumpier\" objective functions.  Suppose you are trying to fit a model to noisy data, and suppose each of your data points has normally-distributed uncertainty.  Then the objective function you would like to minimize could take the form of the sum of several Gaussian distributions, like so:\n",
    "\n",
    "$$f(\\texttt{state}) = \\dfrac{1}{\\sqrt{2\\pi}\\sigma} \\left(e^{-\\dfrac{(\\texttt{state}-\\mu_0)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_1)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_2)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_3)^2}{2\\sigma^2}} + \n",
    "e^{-\\dfrac{(\\texttt{state}-\\mu_4)^2}{2\\sigma^2}}\\right)$$\n",
    "\n",
    "Here, $\\mu_i$ denotes the data points you have, $\\sigma$ is assumed to be an uncertainty shared by all of them, and $\\texttt{state}$ is your model's output, which you want to fit through those data points.\n",
    "\n",
    "If we let $\\sigma=1$, $\\mu_0 = 0$, $\\mu_1 = 2.1$, $\\mu_2 = 4$, $\\mu_3 = 4$ and $\\mu_4 = 8$, then we end up with the following objective function, `several_gaussian_objective(state)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def several_gaussian_objective(state):\n",
    "    locs = [0,2.1,4,4,8] # centers of a bunch of normal distributions\n",
    "    objective_value = 0\n",
    "    # objective function is actually just the sum of a bunch of normal pdfs\n",
    "    for loc in locs:\n",
    "        objective_value += stats.norm.pdf(state, loc=loc, scale=1)\n",
    "    return objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot up this new objective function as a function of `state`.  What do you notice?  Will our \"vanilla\" hill-climbing routine successfully climb the hill and maximize this objective function for *any* initial state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check about where the global maximum is fairly easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(zip(fx, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify our vanilla hill-climbing solution approach from **(1b)** to include 500 random restarts for the initial state.\n",
    "\n",
    "The following code snippet will draw `n_restarts` random samples from the range $[0, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = np.random.random(size=n_restarts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify that to draw instead from the range $[-2, 10)$.  Use those samples to create an **ensemble** of the values of `state` for which the objective function is maximized.  Plot a histogram of them, and make a conclusion about what the \"best guess\" for the maximal `state` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://www.metalsupermarkets.com/wp-content/uploads/2015/09/Heat-Treating-Furnace-2.jpg\" width=\"300\"/>\n",
    "\n",
    "<a/ id='p2'></a>\n",
    "\n",
    "## Problem 2: Simulated annealing\n",
    "\n",
    "<a/ id='p2a'></a>\n",
    "\n",
    "### (2a) \n",
    "\n",
    "First, we need to either create a new class for a simulated annealing `problem`, or sub-class our `problem` class from earlier. That shouldn't be too bad - the main difference is that instead of the best move at any given point, we need to select a random one.\n",
    "\n",
    "In addition to the `objective_function` argument during construction, we also ought to include the `schedule_function` for the temperature updates as time goes on (which moderate how likely we are to take sub-optimal steps). (We will define that one next!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class problem_anneal(problem):\n",
    "\n",
    "    # it's subclassing time!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p2b'></a>\n",
    "\n",
    "### (2b)  Find a temperature schedule\n",
    "\n",
    "Now, we need to actually write our code for the simulated annealing algorithm.  That's a bit more involved than the hill-climbing.\n",
    "\n",
    "The trickiest part is deciding the form for (1) the temperature/time schedule $T(t)$ ($T$ is temperature, $t$ is time), and (2) the accept/reject probability as a function of temperature and the difference in model performance between our current and proposed moves, $\\Delta E$.\n",
    "\n",
    "First, let's play around with the **temperature schedule**.  A typical choice might look like:\n",
    "\n",
    "$$T(t) = \\dfrac{C}{(t+1)^p}$$\n",
    "\n",
    "where $C$ and $p$ are some constants you can tune. The +1 in the denominator is to avoid divide-by-0 situations. \n",
    "\n",
    "Now a typical choice for the probability of accepting a move, based on $\\Delta E = f(\\text{current state}) - f(\\text{proposed state})$ (where $f$ is the objective function that we want to *minimize* here) is:\n",
    "\n",
    "$$p_{accept} = \\exp{\\left(\\dfrac{\\Delta E}{T(t)}\\right)}$$\n",
    "\n",
    "Note that:\n",
    "1. if we wanted instead to *maximize* $f$, we just need to throw a $-$ sign in front of $\\Delta E$, and\n",
    "2. if we find that $f(\\text{proposed state}) < f(\\text{current state})$, then $\\Delta E > 0$ and we should accept the move with $p_{accept} = 1$.\n",
    "\n",
    "That form for $p_{accept}$ is based loosely off of Newton's Law of Cooling and good old-fashioned thermodynamics.  Say what you will about Newton ([he was a jerk](https://jencyclopedic.wordpress.com/2014/04/02/isaac-newton-was-a-dick/)), but his law of cooling is pretty nice.\n",
    "\n",
    "See if you can choose $C$ and $p$ such that the acceptance probability $p_{accept}$ starts near 1 and decreases smoothly to somewhere between 0 and 20% for $t$ ranging from 0 to 1,000.\n",
    "For these preliminary tests, let's just assume that $\\Delta E$ is constant at $\\Delta E = -0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with these choices for $C$ and $p$, we can define a `schedule(time)` function for $T(t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(time):\n",
    "    '''some sort of mapping from time to temperature, to represent how we should be \n",
    "    \"cooling off\" - that is, accepting wacky solutions with lower and lower probability'''\n",
    "\n",
    "    C = #\n",
    "    p = #\n",
    "    temperature = C/(time+1)**p\n",
    "    \n",
    "    return temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p2c'></a>\n",
    "\n",
    "### (2c)  Define our simulated annealing algorithm\n",
    "\n",
    "Now that we have a temperature updating `schedule`, which defines how we accept/reject proposed moves for our simulated annealing algorithm, we can actually turn our pseudocode into real code!\n",
    "\n",
    "Let's write a `simulated_annealing` algorithm. Similar to the `hill_climbing` one above, we should take as arguments only the `problem` statement and maybe one other argument for the number of iterations to run the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulated_annealing(problem, some number of iterations):\n",
    "        \n",
    "    for t in some number of iterations:\n",
    "        #1. update the \"temperature\", T(t) = schedule(time)\n",
    "        #2. which moves can we make from the current node?\n",
    "        #3. pick a random move\n",
    "        #4. calculate difference in objective function between\n",
    "        #   proposed new state and the current state (deltaE)\n",
    "        #5. if proposed new state is better than the current state,\n",
    "        #   then accept the proposed move with probability 1\n",
    "        #6. otherwise...\n",
    "        #        ACCEPT the move with probability exp(-deltaE/T(t)),\n",
    "        #     or REJECT with prob 1-exp(-deltaE/T(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='p2d'></a>\n",
    "\n",
    "### (2d) Let's solve that problem from class!\n",
    "\n",
    "It's time for Tony to reveal a deep, dark secret...\n",
    "\n",
    "You know that plot in class of an example objective function we wanted to use simulated annealing to minimize?\n",
    "\n",
    "Well...  it's just the `several_gaussian_objective` from **(1d)** but ***upside-down!!!***\n",
    "\n",
    "(You should feel free to rename this function...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_such_a_mystery_anymore_objective(state):\n",
    "    locs = [0,2.1,4,4,8] # centers of a bunch of normal distributions\n",
    "    objective_value = 0\n",
    "    # objective function is actually just the sum of a bunch of normal pdfs\n",
    "    for loc in locs:\n",
    "        objective_value += stats.norm.pdf(state, loc=loc, scale=1)\n",
    "    return 1-objective_value\n",
    "\n",
    "x = np.arange(start=-5, stop=15, step=0.1)\n",
    "fx = [not_such_a_mystery_anymore_objective(xk) for xk in x]\n",
    "\n",
    "plt.plot(x, fx, c='coral', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to use our simulated annealing algorithm to solve this problem!\n",
    "1. Define an `initial_state` and declare a relevant `problem`\n",
    "2. Feed these into your simulated annealing algorithm to attempt to find the global minimum\n",
    "\n",
    "If you're having trouble hitting the global minimum, try playing around with different values for:\n",
    "* stepsize (taking tiny steps makes it harder to get out of a local minimum)\n",
    "* schedule (mapping from time to temperature - if you lower the temperature slowly enough, the algorithm *will* find the global minimum with probability approaching 1)\n",
    "* start with initial `state` that you know should lead into the \n",
    "* try using a **random restart** range of initial states, similarly to how we tackled this problem (upside-down) using hill-climbing, and plotting a histogram of the ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='bottom'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
