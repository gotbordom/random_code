{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3202, Spring 2018\n",
    "# Assignment 2\n",
    "# Due: Monday 12 February 2018 by 12:00 PM\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name: Anthony Tracy\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note:** Some helper functions and unit tests are defined at [the bottom of this notebook](#helpers)\n",
    "\n",
    "Shortcuts:  [top](#top) || [1](#p1) | [1a](#p1a) | [1b](#p1b) | [1c](#p1c) | [1d](#p1d) | [1e](#p1e) | [1f](#p1f) || [2](#p2) | [2a](#p2a) | [2b](#p2b) | [2c](#p2c) || [3](#p3) | [3a](#p3a) | [3b](#p3b) | [3c](#p3c) || [4](#p4) | [4a](#p4a) | [4b](#p4b) | [4c](#p4c) | [4d](#p4d) | [4e](#p4e) || [helpers](#helpers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"https://static.rogerebert.com/uploads/movie/movie_poster/escape-from-la-1996/large_edJzJali1V5PS7dCMyLt8cPf3DG.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/>\n",
    "\n",
    "\n",
    "<a id='p1'></a>[top](#top)\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "### Escape from Chicago\n",
    "\n",
    "It is the year 2030 and a freak earthquake has caused Chicago to break off from the mainland of Illinois. It has drifted out into Lake Michigan and is now used as a penal colony for the United States' worst criminals.  Snake Plisskin, world-famous tough guy and amateur sea lion enthusiast, must travel from Chicago to New York to find the antidote to the *Plutoxin 7 poison* that he and many other Chicagoans have been infected with.\n",
    "\n",
    "Below are crude graphs representing the northeastern United States.  The graph on the left, **map_distances**, represents the step costs between two states on the graph (cities) using the distance between the two cities along major highways.  On the right, **map_times** represents the step costs using estimated travel time (at 5 PM on a Friday, east coast time).  These graphs are defined in the helper routines at the bottom of the notebook.\n",
    "\n",
    "If you take a look at those graphss, you will notice that for brevity's sake, we will use **lowercase** abbreviations for each city, consisting of the **first 3 letters** of the city's name.  So Providence is represented by the state 'pro', for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map_distances**          |  **map_times**\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1j6Kam3F7ET-aIzT-6KMxaW7D7r8WAOME\" alt=\"Drawing\" style=\"width: 550px;\"/>  | <img src=\"http://drive.google.com/uc?export=view&id=1rI5w8CuWOS9reMIewc2IDBp_Z3pSUu1H\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1a'></a>\n",
    "### (1a)\n",
    "\n",
    "#### Breadth-first search\n",
    "\n",
    "Implement a function **breadth_first(start, goal, state_graph, return_cost)** to search the state space (and step costs) defined by **state_graph** using breadth-first search:\n",
    "* **start**: initial state (e.g., 'ind')\n",
    "* **end**: goal state (e.g., 'bos')\n",
    "* **state_graph**: the dictionary defining the step costs (e.g., `map_distances`)\n",
    "* **return_cost**: logical input representing whether or not to return the solution path cost\n",
    "  * If **True**, then the output should be a tuple where the first value is the list representing the solution path and the second value is the path cost\n",
    "  * If **False**, then the only output is the solution path list object\n",
    "\n",
    "Note that in the helper functions, two useful routines for obtaining your solution path are provided (and can be used for all the search algorithms):\n",
    "  * **path(previous, s)**: returns a list representing a path to state **s**, where **previous** is a dictionary that maps predecessors (keys) to successors (values)\n",
    "  * **pathcost(path, step_costs)**: adds up the step costs defined by the **step_costs** graph (e.g., `map_distances`) along the list of states **path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither test or bos are in the map\n",
      "[]\n",
      "Neither bos or test are in the map\n",
      "('inf', [])\n"
     ]
    }
   ],
   "source": [
    "## Just some testing to get used to graphs being used:\n",
    "map_distances['chi']\n",
    "\n",
    "## Kind of want to try this without those helpers first..\n",
    "# Reminder - BFS uses a FIFO queue.\n",
    "def breadth_first(start,goal,state_graph,return_cost):\n",
    "    # Make sure the start and goal exist:\n",
    "    path=[]\n",
    "    cost=\"inf\"\n",
    "    # Find goal from start:\n",
    "    if start in state_graph and goal in state_graph:\n",
    "        pass\n",
    "    # Goal & Start don't exist:\n",
    "    else:\n",
    "        print('Neither {0} or {1} are in the map'.format(start,goal))\n",
    "        return (cost,path) if return_cost else path\n",
    "\n",
    "    \n",
    "    \n",
    "# Testing:\n",
    "print(breadth_first('test','bos',map_distances,0))\n",
    "print(breadth_first('bos','test',map_distances,1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test: BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tests_to_run = unittest.TestSuite()\n",
    "tests_to_run.addTest(Tests_Problem1(\"test_bfs\"))\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1b'></a>\n",
    "### (1b)\n",
    "\n",
    "#### Depth-first search\n",
    "\n",
    "Implement a function **depth_first(start, goal, state_graph, return_cost)** to search the state space (and step costs) defined by **state_graph** using depth-first search:\n",
    "* **start**: initial state (e.g., 'ind')\n",
    "* **end**: goal state (e.g., 'bos')\n",
    "* **state_graph**: the dictionary defining the step costs (e.g., `map_distances`)\n",
    "* **return_cost**: logical input representing whether or not to return the solution path cost\n",
    "    * If **True**, then the output should be a tuple where the first value is the list representing the solution path and the second value is the path cost\n",
    "    * If **False**, then the only output is the solution path list object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test: DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tests_to_run = unittest.TestSuite()\n",
    "tests_to_run.addTest(Tests_Problem1(\"test_dfs\"))\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1c'></a>\n",
    "### (1c)\n",
    "\n",
    "#### Uniform-cost search\n",
    "\n",
    "First, let's create our own `Frontier_PQ` class to represent the frontier (priority queue) for uniform-cost search.  Note that the `heapq` package is imported in the helpers at the bottom of this notebook; you may find that package useful.  You could also use the `Queue` package.  Your implementation of the uniform-cost search frontier should adhere to these specifications:\n",
    "* Instantiation arguments: \n",
    "  * **Frontier_PQ(start, cost)**\n",
    "  * **start** is the initial state (e.g., **start**='chi')\n",
    "  * **cost** is the initial path cost (what should it be for the initial state?)\n",
    "* Instantiation attributes/methods:\n",
    "  * **states**: maintains a dictionary of states on the frontier, along with the _minimum_ path cost to arrive at them\n",
    "  * **q**: a list of (cost, state) tuples, representing the elements on the frontier; should be treated as a priority queue (in contrast to the **states** dictionary, which is meant to keep track of the lowest-cost to each state)\n",
    "  * appropriately initialize the starting state and cost\n",
    "* Methods to implement:\n",
    "  * **add(state, cost)**: add the (cost, state) tuple to the frontier\n",
    "  * **pop()**: return the lowest-cost (cost, state) tuple, and pop it off the frontier\n",
    "  * **replace(state, cost)**: if you find a lower-cost path to a state that's already on the frontier, it should be replaced using this method.\n",
    "  \n",
    "Note that there is some redundancy between the information stored in **states** and **q**. I only suggest to code it in this way because I think it's the most straightforward way to get something working. You could reduce the storage requirements by eliminating the redundancy, but it increases the time complexity because of the function calls needed to manipulate your priority queue to check for states (since that isn't how the frontier queue is ordered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, actually implement a function to search using `uniform_cost` search, called as **uniform_cost(start, goal, state_graph, return_cost)**:\n",
    "* **start**: initial state\n",
    "* **goal**: goal state\n",
    "* **state_graph**: graph representing the connectivity and step costs of the state space (e.g., **map_distances** or **map_times** below)\n",
    "* **return_cost**: logical input representing whether or not to return the solution path cost\n",
    "  * If **True**, then the output should be a tuple where the first value is the list representing the solution path and the second value is the path cost\n",
    "  * If **False**, then the only output is the solution path list object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test: uniform-cost search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tests_to_run = unittest.TestSuite()\n",
    "tests_to_run.addTest(Tests_Problem1(\"test_ucs\"))\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1d'></a>\n",
    "### (1d)\n",
    "\n",
    "In the code cell below, use a few **print** statements to showcase the output of each of your three search algorithms defined above (in **1a**, **1b** and **1c**) to find routes for Snake to travel from Chicago to New York, with path costs defined by the distance between cities.\n",
    "\n",
    "Then, in the markdown cell below your code cell, write a few sentences:\n",
    "* Which algorithm yields the shortest path?\n",
    "* Why does this not surprise you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1e'></a>\n",
    "### (1e)\n",
    "\n",
    "The Plutoxin 7 poison (which Snake has been infected with) will cause Snake's central nervous system to implode after exactly 940 minutes.\n",
    "\n",
    "Will any of the paths found in **(1d)** get Snake to New York alive?  Show your work! Snake's life hangs in the balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1f'></a>\n",
    "### (1f)\n",
    "\n",
    "Since time is a factor, Snake ought to optimize his route from Chicago to New York to minimize the total time required. Because Snake is a renaissance man, he knows some pretty slick search algorithms.  But because he's infected with deadly poison, Snake just isn't up to the task of implementing them - his code is full of bugs and he keeps sneezing all over his monitor!  Let's help him out, shall we?\n",
    "\n",
    "In the code cell below, find the shortest path from Chicago to New York as measured by total time taken, and display the result using a **print** statement\n",
    "\n",
    "In the markdown cell below the code cell, write a couple of sentences:\n",
    "* Why did you choose the search algorithm and state space graph that you chose?\n",
    "* Would the solution path found by the other algorithms (the ones you didn't use in your function call) change if you tried to optimize based on time as opposed to distance (i.e., used **map_times** as opposed to **map_distances**)? Why or why not?\n",
    "* **Most importantly:**  will Snake get to New York in time to receive the Plutoxin 7 antidote? This answer should be justified by your code output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<a id='p2'></a>[top](#top)\n",
    "## Problem 2\n",
    "\n",
    "### An uncertain world\n",
    "\n",
    "In the fabled \"real world\", the step costs in terms of travel time between connected cities are estimates; there is **uncertainty** in these estimates.  **For the rest of this problem** we will only refer to the step costs in the **map_times** graph as the step costs (since the distances between two cities have pretty much no uncertainty, they aren't particularly interesting here).  In this problem, we will fit some probability distributions to the step costs, then we will use **Monte Carlo** sampling to estimate the probability that Snake will arrive in New York in time to take the Plutoxin 7 antidote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's think about what these probability distributions should look like in the first place.\n",
    "\n",
    "The step costs represent the time it takes to drive between two cities. These quantities should be nonnegative, have a peak near some central value, and have no theoretical upper bound. Two distributions come to mind, although there are other defensible choices:  lognormal and gamma. For this problem, we will use lognormal distributions.\n",
    "\n",
    "With step cost between two given cities distributed lognormally, this means that the distribution of the natural logarithm of the step costs is normally distributed with mean $\\mu$ and standard deviation $\\sigma$.  It is often more natural to think of the *step cost* median $m = \\exp(\\mu)$, since it is in the same terms (units) as the actual step cost distribution that we care about. $m$ or $\\mu$, together with a shape parameter $\\sigma$, fully define the lognormal distribution for any given step cost in our graph.\n",
    "\n",
    "The next second question is how should we choose $m$ and $\\sigma$ for a given step cost between states?  A natural choice for $m$ is the fixed step costs in **map_times**, since those are central estimates already.\n",
    "\n",
    "Recall that for a normal distribution there is a rule-of-thumb (arising from the Central Limit Theorem) that says that if you draw a large sample from this distribution, about 68% of the samples will come from the interval $[\\mu - \\sigma, \\mu + \\sigma]$, where $\\mu$ and $\\sigma$ and the mean and standard deviation of the normal distribution.  There is a similar rule for the lognormal distribution.  This rule is that about 68% of the samples drawn from a lognormal distribution with parameters $m$ and $s=\\exp{(\\sigma)}$ will come from the interval $[m/s, ms]$.\n",
    "\n",
    "Let's somewhat arbitrarily assume that the uncertainty varies proportionally with the central estimate of the step cost. This should make a bit of sense, because you are generally more uncertain about your arrival time for longer trips. Let's suppose $s = 1.1$, which assumes (roughly) a $\\pm$10% relative error in our central estimate $m$. Note that $s$ will remain the same for all of the steps between states, but $m$ will depend on which step we are looking at.\n",
    "\n",
    "Phew!  Enough chit chat.  Let's do some science!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p2a'></a>\n",
    "### (2a)\n",
    "\n",
    "For the very first step along Snake's minimum-time route from Chicago to New York... \n",
    "* set $m$ equal to the central estimate of this step cost,\n",
    "* set $\\sigma$ equal to $\\log{s} = \\log{1.1}$,\n",
    "* sample 10,000 step costs for this leg of the journey,\n",
    "* and store the resulting sample of step costs in a list.\n",
    "\n",
    "Plot a histogram of the sampling of step costs. Be sure to **label your axes appropriately, including units**. Also, plot the histogram **normalized** to represent a probability distribution, as opposed to a frequency plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p2b'></a>\n",
    "### (2b)\n",
    "\n",
    "Now we need to sample the uncertainty in the remaining steps along the path from Chicago to New York.  It will be easier to simply redo the work from **2a**, but in a more efficient manner. We can be a bit more clever with the foresight that what we *really* want to do is to draw a sample from the distribution of each the step along the path and add them up to obtain a stochastic realization of the total path cost. But it is wildly inefficient to draw once from the distribution for Step 1, then once from Step 2, and so on to the last Step, and then circle back to draw a second time from Step 1, and then a second time from Step 2, and so on ... thousands of times over.\n",
    "\n",
    "So instead...\n",
    "* use a `numpy` array\n",
    "* use zero or one `for` loop\n",
    "* draw 10,000 samples for the time needed for each leg of the journey\n",
    "* obtain a list or array that represents 10,000 samples from the distribution of total path costs\n",
    "\n",
    "Plot a histogram of the sampling of total path costs. Be sure to **label your axes appropriately, including units**, and **normalize** the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p2c'></a>\n",
    "### (2c)\n",
    "\n",
    "Estimate the probability that Snake makes it to New York alive, now that we have taken uncertainty into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<a id='p3'></a>[top](#top)\n",
    "## Problem 3\n",
    "\n",
    "Consider this maze, where gray tiles represent walls and orange tiles represent open space where you can walk.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1bCT7aePAwB1t8ZdIboOqmhzMAQ_grKBZ\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "We can represent this maze using a binary `numpy` array as follows, where 1s represent walls and 0s represent open space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maze = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
    "                 [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
    "                 [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1],\n",
    "                 [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
    "                 [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1],\n",
    "                 [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very importantly**, note that the *first* row of the **maze** array corresponds to the *bottom* row of tiles in the figure.  This is a choice made carefully to reflect the fact that we are going to search for a solution path through this maze in *physical* space, so it is useful for our coordinate system to match Cartesian coordinates. This is in contrast to using the first row of the **maze** array to represent the top of the maze, which looks intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p3a'></a>\n",
    "### (3a)\n",
    "\n",
    "Write a function **maze_to_graph(maze)** that:\n",
    "* takes as input a binary maze **maze**, stored as a `numpy` array, where 0 represents an open space and 1 represents a wall\n",
    "* returns a graph dictionary in a similar style to **map_distances** and **map_times** (from Problem 1)\n",
    "  * the keys are tuples giving the states (coordinate pairs) within the maze (e.g., (1,1) represents the lower-left open space, (2,1) represents the space **to the right** of (1,1), and (0,0) represents the lower-left corner, a wall location); thus, the coordinates within the maze are like Cartesian coordinates, and the x- and y-axes are the bottom and left walls of the maze, respectively\n",
    "  * the values are themselves dictionaries, where the keys are other states within the maze and the values are the actions taken to move to that state\n",
    "  * the actions are moves from the list ['N','S','E','W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test: maze-to-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run unit tests\n",
    "tests = Tests_Problem3()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p3b'></a>\n",
    "### (3b)\n",
    "\n",
    "Use you **maze_to_graph** function and **depth-first search** to solve the maze defined above.  A simple 'print' statement of the path your codes find and its length suffices.\n",
    "* The initial state is (1,1)\n",
    "* The goal state is (10,10)\n",
    "\n",
    "Then, use your **breadth-first search** function to solve the maze; provide the solution path and its length.\n",
    "\n",
    "If your codes are sufficiently general, the output from **maze_to_graph** should be suitable to be fed straight into your search routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p3c'></a>\n",
    "### (3c)\n",
    "\n",
    "Write a function **plot_maze(maze, path)** that takes as input a binary `numpy` array **maze** (1s represent walls, 0s represent open space) and a solution **path**, and plots the two together.\n",
    "* **maze**: a maze represented as a binary `numpy` array, as above\n",
    "* **path**: a solution path found using your search algorithms above. **path** should be consistent with the output from the **path** function below in the helpers (a list of states).  You may find it useful to provide a default of `None` for **path**, so that you can use your function to just plot a maze that you haven't solved yet.\n",
    "\n",
    "Then, use your **plot_maze** function to plot the maze defined above, along with the solution path found by **depth-first search**.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Potentially useful:** \n",
    "\n",
    "[1] In the helpers, you will notice that there are two packages imported:\n",
    "  * `import matplotlib.pyplot as plt`\n",
    "  * `from matplotlib import colors`\n",
    "\n",
    "`pyplot` and `colors` may be potentially useful to you for generating a pretty plot and generating a colormap for your walls/open spaces in the maze, respectively.  You do not need to use them, but I wanted to provide this nudge for folks who maybe have not done much/any plotting in Python before.\n",
    "\n",
    "[2] Also, [Color Oracle](http://colororacle.org/) is a useful utility for making colorblind-friendly plots. If you ever plan to show another human being a figure that you have generated, this is nice practice. Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<a id='p4'></a>[top](#top)\n",
    "## Problem 4\n",
    "\n",
    "<img src=\"https://cdn.cinnabon.com/-/media/cinnabon/menu/minibon_332x255.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "### The Cinnabonmageddon Loss Function\n",
    "\n",
    "To motivate this problem, consider the following situation.  Suppose you need to drive your friend Dan to the airport.  Let $d$ represent your decision, namely, how long you and Dan allow for the trip to the airport.  Let $x$ represent the amount of time it actually takes you to drive to the airport. Common experience suggests that $x$ is uncertain, and we would like to account for this uncertainty in our decision about when to leave.\n",
    "\n",
    "Also, let $L(d,x)$ represent the loss function when decision $d$ is made in state $x$. \n",
    "\n",
    "So, for example, $d=180$ minutes if we leave 3 hours before Dan wants to arrive at the airport, and $x=45$ minutes would represent the state-of-the-world (SOW) where it actually takes you 45 minutes to drive there. And $L(180,45)$ is the resulting loss.  We feel this loss because we have most likely arrived at the airport about 2 hours ahead of schedule and will now sit and eat Cinnabon and regret our decisions - *all* of our decisions.\n",
    "\n",
    "For the loss function, let's use the classical **plane-catching loss function**, also known as the **catastrophic** - or in the case of airports, **Cinnabonmageddon** - **loss function**:\n",
    "\n",
    "$$L(d,x) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "             k(d-x) & \\quad d \\ge x \\\\\n",
    "             k(d-x)+M & \\quad d < x\n",
    "        \\end{array}\n",
    "    \\right.$$\n",
    "    \n",
    "Here, $k$ and $M$ are positive constants, and we assume that $M > k(d-x)$ for any situations we care about. $M$ represents the catastrophic increase in loss from missing our plane, and since we have several hours to kill in the airport before the next flight, we eat Cinnabon (which only compounds the loss we suffer).\n",
    "\n",
    "As we saw in class, the expected value of perfect information (EVPI) and the expected value of including uncertainty (EVIU) in your decision regarding when to leave for the airport depend on two subjective judgments:\n",
    "1. the functional form of the loss function, $L(d,x)$, and\n",
    "1. the prior probability density function (pdf), $f(x)$, over all possible SOW, $x$.\n",
    "\n",
    "This problem is meant partially to give you experience working in Markdown, and also partially meant to give you experience getting used to the mechanics of manipulating tricky loss functions, and obtaining useful results regarding the theoretical value of including or reducing uncertainty in our probabilistic estimates, which in turn, affects the decisions we or our robot overlords will make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p4a'></a>\n",
    "### (4a)\n",
    "\n",
    "Show that the Bayes' Decision ($d_B$, the decision that minimizes the expected loss) for the plane-catching problem defined here satisfies the equation:  $$\\ f(d_B) = \\dfrac{k}{M}$$\n",
    "\n",
    "Do all of your work in Markdown below, with LaTeX formatting for equations.\n",
    "\n",
    "**Hint:**  Recall that if $F(x)$ is the cumulative density function corresponding to the probability density function $f(x)$, then ${\\displaystyle F(x) = \\int_{-\\infty}^x f(y)\\ dy}$ and $f(x) = \\dfrac{d}{dx} F(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p4b'></a>\n",
    "### (4b)\n",
    "\n",
    "To proceed any further, we need a prior distribution $f(x)$.  Let's again use a lognormal distribution.  The probability density function for a lognormal distribution looks like:\n",
    "\n",
    "$$f(x) = f(x~|~\\mu, \\sigma) = \\dfrac{1}{\\sqrt{2\\pi}\\ \\sigma\\ x}\\ \\exp{\\left[-\\dfrac{(\\log{(x)} - \\mu)^2}{2\\sigma^2}\\right]}$$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ are the parameters discussed in Problem 2. For brevity's sake, we will leave off the conditioning of this probability density function on $\\mu$ and $\\sigma$.\n",
    "\n",
    "If we combine this prior distribution with our constraint for the Bayes' Decision from **4a**, we find:\n",
    "\n",
    "$$f(d_B) = \\dfrac{1}{\\sqrt{2\\pi}\\ \\sigma\\ d_B}\\ \\exp{\\left[-\\dfrac{(\\log{(d_B)} - \\mu)^2}{2\\sigma^2}\\right]} \\stackrel{\\heartsuit}{=} \\dfrac{k}{M}$$\n",
    "\n",
    "Starting from the equation above, show that the Bayes' Decision $d_B$ satisfies the following equation:\n",
    "\n",
    "$$\\log{d_B} = \\mu - \\sigma^2 \\pm \\sigma \\sqrt{\\sigma^2 - 2\\mu - 2\\log{\\left(\\dfrac{\\sqrt{2\\pi}\\sigma k}{M}\\right)}}$$\n",
    "\n",
    "**Hint:**  You will need to use the quadratic formula (that's where the $\\pm$ comes into play)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p4c'></a>\n",
    "### (4c)\n",
    "\n",
    "Write a function **expected_loss(d, k, M, mu, sigma)** to calculate the expected loss with the following inputs:\n",
    "* **d** is the decision that is made (i.e., how long you allow for travel to the airport)\n",
    "* **k** and **M** are parameters from the loss function specification\n",
    "* **mu** is the central tendency parameter from the lognormal prior distribution (**mu** = $\\log{m}$ from Problem 2)\n",
    "* **sigma** is the uncertainty parameter from the lognormal prior distribution (**sigma** = $\\log{s}$ from Problem 2)\n",
    "* return the expected loss using the catastrophic/plane-catching/Cinnabonmageddon loss function\n",
    "\n",
    "Note that somewhere in your intermediate work for **4a**, you should have stumbled upon an expression for the expected loss under decision $d$ (since this is what you must minimize to find the Bayes' Decision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your **expected_loss** function to determine the Bayes' Decision, using these parameters:\n",
    "* $k=1$\n",
    "* $M=300$ (minutes)\n",
    "* $\\mu = \\log{50}$\n",
    "* $\\sigma = \\log{1.2}$  (reflecting that we have driven on I-70 near Denver before, and are therefore more uncertain about this travel time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a bit more certain about how long it will take to get to the airport. You might represent this knowledge by reducing $\\sigma$ to $\\sigma=\\log{1.1}$. What then would be the Bayes' Decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a sentence or two reflecting on the relationship between your uncertainty regarding travel time and the Bayes' Decision for how long to allow for the trip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p4d'></a>\n",
    "### (4d)\n",
    "\n",
    "#### EVIU and EVPI\n",
    "\n",
    "Recall that the expected value of perfect information (EVPI) and the expected value of including uncertainty (EVIU) are:\n",
    "\n",
    "$$\\begin{align*}\n",
    "  \\text{EVPI} &= E_x[L(d_B, x)] - E_x[L(d_{pi}, x)] \\\\\n",
    "  \\text{EVIU} &= E_x[L(d_{iu}, x)] - E_x[L(d_{B}, x)] \n",
    " \\end{align*}$$\n",
    "\n",
    "where $d_{iu}$ is the decision you would make ignoring uncertainty, $d_{pi}$ is the decision you would make if you had perfect information regarding the uncertain travel time $x$, and $d_B$ is the Bayes' Decision.\n",
    "\n",
    "In **4c** you computed the Bayes' Decision ($d_B$) and its expected loss ($E_x[L(d_B,x)]$), and wrote a nice function for expected loss that we can simply plug in $d_{iu}$ and $d_{pi}$ into, and we will have everything we need to calculate EVPI and EVIU!\n",
    "\n",
    "First, if we had perfect information, we would know exactly the value of $x$ and could make the decision $d_{pi}=x$.  So $L(d_{pi}, x)=0$, and EVPI reduces to\n",
    "\n",
    "$$\\text{EVPI} = E_x[L(d_B, x)]$$\n",
    "\n",
    "Next, let's suppose that if we were to ignore uncertainty, we would decide to leave the expected amount of time for the journey to the airport.  Thus, we might take $d_{iu} = E_x[x]$.\n",
    "\n",
    "Calculate the EVPI and the EVIU for the parameters given in **4c** (with the original $\\sigma=\\log{1.2}$). Note that there is a lovely closed form for the expected value of a lognormally distributed random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p4e'></a>\n",
    "### (4e)\n",
    "\n",
    "#### How uncertain are we?\n",
    "\n",
    "Our decisions hinge on how certain/uncertain we are about the world around us.  For this particular problem, our uncertain decision variable is how long it will take to drive to the airport.\n",
    "\n",
    "Let's see how our estimates of the EVPI and EVIU vary, depending on how uncertain we are. Calculate EVIU and EVPI for a range of values of $\\sigma$, the uncertainty parameter for the lognormal prior distribution (the first line given below provides which values for $\\sigma$ you should use).\n",
    "\n",
    "Then, plot the results.\n",
    "* plot $\\sigma$ along the x-axis\n",
    "* plot EVIU and EVPI on the same y-axis\n",
    "* include a legend pointing out which line is EVIU and which one is EVPI\n",
    "* label your axes appropriately\n",
    "\n",
    "Lastly, include a few sentences in a Markdown cell reflecting on what the shape of this plot tells you.  For example, how do the relative values of EVPI and EVIU change as your uncertainty $\\sigma$ changes? Does the way in which increasing uncertainty affect EVIU and EVPI make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = np.log(np.arange(1, 3, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<a id='helpers'></a>\n",
    "\n",
    "---\n",
    "\n",
    "[top](#top)\n",
    "\n",
    "## Some things that are useful\n",
    "\n",
    "Easiest way to start:  Click this cell, go to \"Cell\" in the toolbar above, and click \"Run All Below\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from collections import deque\n",
    "import heapq\n",
    "import unittest\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful routines for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['chi', 'cle', 'buf'])\n",
      "dict_values([283, 169, 256])\n"
     ]
    }
   ],
   "source": [
    "def path(previous, s): \n",
    "    '''\n",
    "    `previous` is a dictionary chaining together the predecessor state that led to each state\n",
    "    `s` will be None for the initial state\n",
    "    otherwise, start from the last state `s` and recursively trace `previous` back to the initial state,\n",
    "    constructing a list of states visited as we go\n",
    "    '''\n",
    "    if s is None:\n",
    "        return []\n",
    "    else:\n",
    "        return path(previous, previous[s])+[s]\n",
    "\n",
    "def pathcost(path, step_costs):\n",
    "    '''\n",
    "    add up the step costs along a path, which is assumed to be a list output from the `path` function above\n",
    "    '''\n",
    "    cost = 0\n",
    "    for s in range(len(path)-1):\n",
    "        cost += step_costs[path[s]][path[s+1]]\n",
    "    return cost\n",
    "\n",
    "\n",
    "keys = map_distances['det'].keys()\n",
    "vals = map_distances['det'].values()\n",
    "\n",
    "print(keys)\n",
    "print(vals)\n",
    "\n",
    "so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_distances = dict(\n",
    "    chi=dict(det=283, cle=345, ind=182),\n",
    "    cle=dict(chi=345, det=169, col=144, pit=134, buf=189),\n",
    "    ind=dict(chi=182, col=176),\n",
    "    col=dict(ind=176, cle=144, pit=185),\n",
    "    det=dict(chi=283, cle=169, buf=256),\n",
    "    buf=dict(det=256, cle=189, pit=215, syr=150),\n",
    "    pit=dict(col=185, cle=134, buf=215, phi=305, bal=247),\n",
    "    syr=dict(buf=150, phi=253, new=254, bos=312),\n",
    "    bal=dict(phi=101, pit=247),\n",
    "    phi=dict(pit=305, bal=101, syr=253, new=97),\n",
    "    new=dict(syr=254, phi=97, bos=215, pro=181),\n",
    "    pro=dict(bos=50, new=181),\n",
    "    bos=dict(pro=50, new=215, syr=312, por=107),\n",
    "    por=dict(bos=107))\n",
    "\n",
    "map_times = dict(\n",
    "    chi=dict(det=280, cle=345, ind=200),\n",
    "    cle=dict(chi=345, det=170, col=155, pit=145, buf=185),\n",
    "    ind=dict(chi=200, col=175),\n",
    "    col=dict(ind=175, cle=155, pit=185),\n",
    "    det=dict(chi=280, cle=170, buf=270),\n",
    "    buf=dict(det=270, cle=185, pit=215, syr=145),\n",
    "    pit=dict(col=185, cle=145, buf=215, phi=305, bal=255),\n",
    "    syr=dict(buf=145, phi=245, new=260, bos=290),\n",
    "    bal=dict(phi=145, pit=255),\n",
    "    phi=dict(pit=305, bal=145, syr=245, new=150),\n",
    "    new=dict(syr=260, phi=150, bos=270, pro=260),\n",
    "    pro=dict(bos=90, new=260),\n",
    "    bos=dict(pro=90, new=270, syr=290, por=120),\n",
    "    por=dict(bos=120))\n",
    "\n",
    "def check_map(step_costs):\n",
    "    ''' function to check if all the path costs are at least symmetric '''\n",
    "    check_states = []\n",
    "    for state1 in step_costs.keys():\n",
    "        for state2 in step_costs[state1].keys():\n",
    "            uh_oh = step_costs[state2][state1]!=step_costs[state1][state2]\n",
    "            if uh_oh:\n",
    "                print('Check the costs between states {} and {}'.format(state1,state2))\n",
    "                check_states.append([state1,state2])\n",
    "    if len(check_states)==0:\n",
    "        print('all okay! (symmetric at least)')\n",
    "    return check_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tests_Problem1(unittest.TestCase):\n",
    "    def test_dfs(self):\n",
    "        path, cost = depth_first('chi','pit',map_distances,True)\n",
    "        self.assertEqual(path, ['chi', 'ind', 'col', 'pit'])\n",
    "        self.assertEqual(path, depth_first('chi','pit',map_times,False))\n",
    "        self.assertEqual(cost, 543)\n",
    "    def test_bfs(self):\n",
    "        path, cost = breadth_first('chi','pit',map_distances,True)\n",
    "        self.assertEqual(path, ['chi', 'cle', 'pit'])\n",
    "        self.assertEqual(path, breadth_first('chi','pit',map_times,False))\n",
    "        self.assertEqual(cost, 479)\n",
    "    def test_ucs(self):\n",
    "        path, cost = uniform_cost('chi','pit',map_distances,True)\n",
    "        self.assertEqual(path, ['chi', 'cle', 'pit'])\n",
    "        self.assertEqual(cost, 479)\n",
    "\n",
    "class Tests_Problem3(unittest.TestCase):\n",
    "    def test_graph2maze(self):\n",
    "        testmaze = np.ones((4,4))\n",
    "        testmaze[1,1] = 0\n",
    "        testmaze[2,1] = 0\n",
    "        testmaze[2,2] = 0\n",
    "        testgraph = maze_to_graph(testmaze)\n",
    "        self.assertEqual(testgraph,{(1, 1): {(1, 2): 'N'}, (1, 2): {(1, 1): 'S', (2, 2): 'E'}, (2, 2): {(1, 2): 'W'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
